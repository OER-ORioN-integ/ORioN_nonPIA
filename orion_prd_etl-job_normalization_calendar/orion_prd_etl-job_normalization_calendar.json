{
  "name" : "orion_prd_etl-job_normalization_calendar",
  "jobMode" : "VISUAL",
  "description" : "MANUAL - カレンダー",
  "role" : "arn:aws:iam::142980225941:role/orion_prd_glue-role",
  "executionProperty" : {
    "maxConcurrentRuns" : 1
  },
  "command" : {
    "name" : "glueetl",
    "scriptLocation" : "s3://orion-prd-etljob/scripts/orion_prd_etl-job_normalization_calendar.py",
    "pythonVersion" : "3"
  },
  "defaultArguments" : {
    "--enable-metrics" : "true",
    "--spark-event-logs-path" : "s3://aws-glue-assets-142980225941-ap-northeast-1/sparkHistoryLogs/",
    "--enable-job-insights" : "false",
    "--enable-glue-datacatalog" : "true",
    "--EXECUTE_TIMESTAMP_ISO_STR" : "2024-01-01T02:34:56.789Z",
    "--SOURCE_SYSTEM" : "MANUAL",
    "--job-bookmark-option" : "job-bookmark-disable",
    "--DATA_NAME" : "calendar",
    "--job-language" : "python",
    "--TempDir" : "s3://orion-prd-etljob/tmp/"
  },
  "maxRetries" : 0,
  "allocatedCapacity" : 2,
  "timeout" : 120,
  "maxCapacity" : 2.0,
  "glueVersion" : "4.0",
  "numberOfWorkers" : 2,
  "workerType" : "G.1X",
  "executionClass" : "STANDARD",
  "codeGenConfigurationNodes" : "{\"node-1727674889392\":{\"S3CsvSource\":{\"AdditionalOptions\":{\"EnableSamplePath\":true,\"SamplePath\":\"s3://orion-prd-work/MANUAL/calendar/schema/calendar_schema.csv\"},\"Escaper\":\"\\\\\",\"Exclusions\":[],\"Name\":\"【必須】連携された匿名化済みのデータ\",\"OptimizePerformance\":false,\"OutputSchemas\":[{\"Columns\":[{\"Name\":\"date\",\"Type\":\"string\"},{\"Name\":\"week\",\"Type\":\"string\"},{\"Name\":\"weekday_holidays\",\"Type\":\"string\"},{\"Name\":\"schedule_type\",\"Type\":\"string\"},{\"Name\":\"holiday_name\",\"Type\":\"string\"},{\"Name\":\"year_month\",\"Type\":\"string\"},{\"Name\":\"quarter\",\"Type\":\"string\"},{\"Name\":\"fiscal_year\",\"Type\":\"string\"}]}],\"Paths\":[\"s3://orion-prd-work/MANUAL/calendar/raw_tmp/\"],\"QuoteChar\":\"quote\",\"Separator\":\"comma\",\"WithHeader\":true}},\"node-1727675890558\":{\"ApplyMapping\":{\"Inputs\":[\"node-1727674889392\"],\"Mapping\":[{\"Dropped\":false,\"FromPath\":[\"date\"],\"FromType\":\"string\",\"ToKey\":\"date\",\"ToType\":\"string\"},{\"Dropped\":false,\"FromPath\":[\"week\"],\"FromType\":\"string\",\"ToKey\":\"week\",\"ToType\":\"string\"},{\"Dropped\":false,\"FromPath\":[\"weekday_holidays\"],\"FromType\":\"string\",\"ToKey\":\"weekday_holidays\",\"ToType\":\"string\"},{\"Dropped\":false,\"FromPath\":[\"schedule_type\"],\"FromType\":\"string\",\"ToKey\":\"schedule_type\",\"ToType\":\"string\"},{\"Dropped\":false,\"FromPath\":[\"holiday_name\"],\"FromType\":\"string\",\"ToKey\":\"holiday_name\",\"ToType\":\"string\"},{\"Dropped\":false,\"FromPath\":[\"year_month\"],\"FromType\":\"string\",\"ToKey\":\"year_month\",\"ToType\":\"string\"},{\"Dropped\":false,\"FromPath\":[\"quarter\"],\"FromType\":\"string\",\"ToKey\":\"quarter\",\"ToType\":\"string\"},{\"Dropped\":false,\"FromPath\":[\"fiscal_year\"],\"FromType\":\"string\",\"ToKey\":\"fiscal_year\",\"ToType\":\"string\"}],\"Name\":\"【必須】データ型を変換\"}},\"node-1740551605129\":{\"CustomCode\":{\"ClassName\":\"DateStringJustify\",\"Code\":\"import re\\nfrom pyspark.sql.functions import col, udf\\nfrom pyspark.sql.types import StringType    \\n\\n### 作成時の修正箇所ここから ###\\n# 入力項目名と出力項目名の設定\\n入力項目名リスト = [\\\"date\\\",]\\n出力項目名リスト = [\\\"date\\\",]\\n### 作成時の修正箇所ここまで ###\\n\\n# 日付文字列の月日部を２桁に揃える\\ndef fmt_date_str(date_str):\\n    if date_str == '':\\n        return None\\n\\n    parts = date_str.split('/')\\n    year = parts[0]\\n    month = parts[1].zfill(2)\\n    day = parts[2].zfill(2)\\n\\n    return f'{year}/{month}/{day}'    \\n\\n# UDFの定義\\nfmt_date_str_udf = udf(fmt_date_str, StringType())\\n\\n# DataFrameの取得\\ndf = dfc.select(list(dfc.keys())[0]).toDF()\\n\\n# UDFを適用して新しいカラムを追加\\nfor 入力項目名, 出力項目名 in zip(入力項目名リスト, 出力項目名リスト):\\n    df = df.withColumn(出力項目名, fmt_date_str_udf(df[入力項目名]))\\n\\n# DynamicFrameに変換して返す\\noutput_dyf = DynamicFrame.fromDF(df, glueContext, \\\"output\\\")\\nreturn DynamicFrameCollection({\\\"CustomTransform0\\\": output_dyf}, glueContext)\\n\",\"Inputs\":[\"node-1727675890558\"],\"Name\":\"【加工】日付文字列の桁揃え\",\"OutputSchemas\":[{\"Columns\":[{\"Name\":\"date\",\"Type\":\"string\"},{\"Name\":\"week\",\"Type\":\"string\"},{\"Name\":\"weekday_holidays\",\"Type\":\"string\"},{\"Name\":\"schedule_type\",\"Type\":\"string\"},{\"Name\":\"holiday_name\",\"Type\":\"string\"},{\"Name\":\"year_month\",\"Type\":\"string\"},{\"Name\":\"quarter\",\"Type\":\"string\"},{\"Name\":\"fiscal_year\",\"Type\":\"string\"}]}]}},\"node-1735205236158\":{\"CustomCode\":{\"ClassName\":\"MyTransformDateFormat\",\"Code\":\"from pyspark.sql.functions import col, lit, regexp_replace, when\\n\\n### 作成時の修正箇所ここから ###\\n# 入力項目名と出力項目名の設定\\n入力項目名リスト = [\\\"date\\\",]\\n出力項目名リスト = [\\\"date\\\",]\\n### 作成時の修正箇所ここまで ###\\n\\n# 入力フォーマット\\nINPUT_FORMAT = r\\\"^\\\\d{4}/\\\\d{2}/\\\\d{2}\\\"\\n\\n# 最小値の設定\\nMIN_YMD = lit(\\\"1900-01-01\\\")\\nMIN_YMD_FORMAT = None\\n\\n# 条件文：\\n#   1)Nullならそのまま\\n#   2)Date文字列で、\\n#       2-1) MIN_YMD より小さいなら MIN_YMD_FORMAT に置換\\n#       2-2)それ以外なら\\\"-\\\"を\\\"/\\\"に置換\\n#   3)Date文字列でないないら、Noneを返す\\ndef mk_cond(col_name: str):\\n    return (\\n        when(col(col_name).isNull(), None)\\n        .when(col(col_name).substr(1, 10).rlike(INPUT_FORMAT),\\n            when(col(col_name).substr(1, 10) < MIN_YMD, MIN_YMD_FORMAT)\\n            .otherwise(regexp_replace(col(col_name).substr(1, 10), \\\"-\\\", \\\"/\\\")))\\n        .otherwise(None)\\n    )\\n\\nconds_dict = {出力項目名: mk_cond(入力項目名) for 入力項目名, 出力項目名 in zip(入力項目名リスト, 出力項目名リスト)}\\n\\n# DataFrameの取得\\ndf = dfc.select(list(dfc.keys())[0]).toDF()\\n\\n# 値のマスキング実施\\ndf = df.withColumns(conds_dict)\\n\\n# DynamicFrameに変換して返す\\noutput_dyf = DynamicFrame.fromDF(df, glueContext, \\\"output\\\")\\nreturn DynamicFrameCollection({\\\"CustomTransform0\\\": output_dyf}, glueContext)\\n\",\"Inputs\":[\"node-1740551674810\"],\"Name\":\"【加工】定義した日付フォーマットに変換\",\"OutputSchemas\":[{\"Columns\":[{\"Name\":\"date\",\"Type\":\"string\"},{\"Name\":\"week\",\"Type\":\"string\"},{\"Name\":\"weekday_holidays\",\"Type\":\"string\"},{\"Name\":\"schedule_type\",\"Type\":\"string\"},{\"Name\":\"holiday_name\",\"Type\":\"string\"}]}]}},\"node-1728609073799\":{\"CustomCode\":{\"ClassName\":\"MyTransformOutputOneFileParquet\",\"Code\":\"from datetime import datetime, timedelta, timezone\\nimport boto3\\nfrom awsglue.utils import getResolvedOptions\\nfrom pyspark.sql import DataFrame\\n\\n### 作成時の修正箇所ここから ###\\n#  本ノードは作成時のパラメータ設定不要です。このままお使いください。\\n### 作成時の修正箇所ここまで ###\\n\\nprint(f\\\"{datetime.strftime(datetime.now(), '%Y/%m/%dT%H:%M:%S')} INFO (MyTransformOutputOneFileParquet) start\\\")\\n\\n# Glueジョブ引数の取得\\nglue_params = getResolvedOptions(sys.argv, [\\\"SOURCE_SYSTEM\\\", \\\"DATA_NAME\\\", \\\"EXECUTE_TIMESTAMP_ISO_STR\\\"])\\nprint(f\\\"{datetime.strftime(datetime.now(), '%Y/%m/%dT%H:%M:%S')} DEBUG (MyTransformOutputOneFileParquet) glue_params:{glue_params}\\\")\\n\\n# 連携元システム名（DMP/ONE/OCTPASS/MANUAL）\\nsource_system = glue_params.get(\\\"SOURCE_SYSTEM\\\", None)\\n# データ名（物理テーブル名）\\ndata_name = glue_params.get(\\\"DATA_NAME\\\", None)\\n# 実行日時\\nexecute_timestamp_iso_str = glue_params.get(\\\"EXECUTE_TIMESTAMP_ISO_STR\\\", None)\\n\\n# プレフィックスヘッド\\nprefix_head = f\\\"{source_system}/{data_name}\\\"\\n\\n# 作業用バケット\\nwork_bucket = \\\"orion-prd-work\\\"\\n# workディレクトリ\\nwork_dir = f\\\"{prefix_head}/raw_work/\\\"\\n# 一時出力先s3パス\\nwork_s3_path = f\\\"s3://{work_bucket}/{work_dir}\\\"\\n\\n# DataFrameの取得\\ndf = dfc.select(list(dfc.keys())[0]).toDF()\\n\\n# workフォルダにparquet形式で出力\\ndf.coalesce(1).write.option(\\\"compression\\\", \\\"snappy\\\").mode(\\\"overwrite\\\").parquet(work_s3_path)\\n\\n# 関数定義\\ndef get_process_timestamp_from_df(df: DataFrame, column_name: str) -> str:\\n    \\\"\\\"\\\"DFからデータ統合基盤処理日時 文字列を取得する\\n    Args:\\n        df (pysoar.sql.DataFrame): データフレーム\\n        column_name (str): データ統合基盤処理日時項目名\\n    Returns:\\n        str: yyyymmddhhmmss\\n    \\\"\\\"\\\"\\n    # JSTタイムスタンプカラムの値を取得（yyyy/mm/dd hh:mm:ss形式）\\n    orion_process_datetm = df.select(column_name).first()[0]\\n    # yyyymmddhhmmss形式に変換\\n    res_datetm_str = datetime.strptime(orion_process_datetm, \\\"%Y/%m/%d %H:%M:%S\\\").strftime(\\\"%Y%m%d%H%M%S\\\")\\n    return res_datetm_str\\n\\ndef convert_timestamp_iso_to_jst(iso_time_str: str, output_format: str) -> str:\\n    \\\"\\\"\\\"ISO日時文字列を指定フォーマットに変換\\n    Args:\\n        iso_time_str (str): ISO日時文字列\\n        output_format (str): 出力フォーマット\\n    Returns:\\n        str: 指定フォーマット形式文字列\\n    \\\"\\\"\\\"\\n    # UTCの日時文字列をパースしてdatetimeオブジェクトに変換\\n    utc_time = datetime.strptime(iso_time_str, \\\"%Y-%m-%dT%H:%M:%S.%fZ\\\")\\n    # JSTへの変換（UTC+9時間）\\n    jst_time = utc_time.replace(tzinfo=timezone.utc).astimezone(timezone(timedelta(hours=9)))\\n    # フォーマット変換\\n    jst_time_str = jst_time.strftime(output_format)\\n    return jst_time_str\\n\\n# ■実行日時をJSTのyyyyymmddhhmmss文字列に変換\\n# DFの処理日時項目名\\nORION_PROCESS_DATETM = \\\"orion_process_datetm\\\"\\nif ORION_PROCESS_DATETM in df.columns and df.select(ORION_PROCESS_DATETM).count() != 0:\\n    execute_timestamp_str = get_process_timestamp_from_df(df=df, column_name=ORION_PROCESS_DATETM)\\n    print(f\\\"{datetime.strftime(datetime.now(), '%Y/%m/%dT%H:%M:%S')} DEBUG (get_process_timestamp_from_df) execute_timestamp_str:{execute_timestamp_str}\\\")\\nelse:\\n    execute_timestamp_str = convert_timestamp_iso_to_jst(iso_time_str=execute_timestamp_iso_str, output_format=\\\"%Y%m%d%H%M%S\\\")\\n    print(f\\\"{datetime.strftime(datetime.now(), '%Y/%m/%dT%H:%M:%S')} DEBUG (convert_timestamp_iso_to_jst) execute_timestamp_str:{execute_timestamp_str}\\\")\\n\\n#  DWHバケット\\ndwh_bucket = \\\"orion-prd-dwh\\\"\\n# 連携先ディレクトリ\\nreceive_prefix = f\\\"{prefix_head}/receive\\\"\\n# 連携ファイル名\\nfile_name = f\\\"{data_name}_dwh_{execute_timestamp_str}.snappy.parquet\\\"\\n# 連携先key\\nfile_key = f\\\"{receive_prefix}/{file_name}\\\"\\n\\n# S3クライアントを使用してworkフォルダに出力したファイルをリネームして移動\\ns3 = boto3.client(\\\"s3\\\")\\ns3_resource = boto3.resource(\\\"s3\\\")\\ntransfer_config = boto3.s3.transfer.TransferConfig(\\n    multipart_threshold=256 * 1024 * 1024,\\n    multipart_chunksize=256 * 1024 * 1024\\n)\\n\\nresponse = s3.list_objects_v2(Bucket=work_bucket, Prefix=work_dir)\\nfor obj in response.get(\\\"Contents\\\", []):\\n    if obj[\\\"Key\\\"].endswith(\\\".parquet\\\"):\\n        # ソース情報設定\\n        copy_source = {\\\"Bucket\\\": work_bucket, \\\"Key\\\": obj[\\\"Key\\\"]}\\n        print(f\\\"{datetime.strftime(datetime.now(), '%Y/%m/%dT%H:%M:%S')} DEBUG (MyTransformOutputOneFileParquet) copy_source:{copy_source}, dwh_bucket:{dwh_bucket}, file_key:{file_key}\\\")\\n        # コピーを実行\\n        s3_resource.meta.client.copy(CopySource=copy_source, Bucket=dwh_bucket, Key=file_key, Config=transfer_config)\\n        # 削除を実行\\n        s3.delete_object(Bucket=work_bucket, Key=obj[\\\"Key\\\"])\\n        break\\n\\nprint(f\\\"{datetime.strftime(datetime.now(), '%Y/%m/%dT%H:%M:%S')} INFO (MyTransformOutputOneFileParquet) end\\\")\\n\",\"Inputs\":[\"node-1731895939959\"],\"Name\":\"【必須】１ファイルでDWHバケットに出力\"}},\"node-1731895901595\":{\"CustomCode\":{\"ClassName\":\"MyTransformAddTimestamp\",\"Code\":\"from datetime import datetime, timedelta, timezone\\nfrom awsglue.utils import getResolvedOptions\\nfrom pyspark.sql.functions import lit\\n\\n### 作成時の修正箇所ここから ###\\n#  本ノードは作成時のパラメータ設定不要で、このままお使いください。\\n### 作成時の修正箇所ここまで ###\\n\\n# print(f\\\"{datetime.strftime(datetime.now(), '%Y/%m/%dT%H:%M:%S')} INFO (MyTransformAddTimestamp) start\\\")\\n\\n# Glueジョブ引数の取得\\nglue_params = getResolvedOptions(sys.argv, [\\\"EXECUTE_TIMESTAMP_ISO_STR\\\"])\\n# print(f\\\"{datetime.strftime(datetime.now(), '%Y/%m/%dT%H:%M:%S')} DEBUG (MyTransformAddTimestamp) glue_params:{glue_params}\\\")\\n\\n# 実行日時\\nexecute_timestamp_iso_str = glue_params.get(\\\"EXECUTE_TIMESTAMP_ISO_STR\\\", None)\\n\\n# 追加項目名\\nadd_column_name = \\\"orion_process_datetm\\\"\\n\\n# 関数定義\\ndef convert_timestamp_iso_to_jst(iso_time_str: str, output_format: str) -> str:\\n    \\\"\\\"\\\"ISO日時文字列を指定フォーマットに変換\\n    Args:\\n        iso_time_str (str): ISO日時文字列\\n        output_format (str): 出力フォーマット\\n    Returns:\\n        str: 指定フォーマット形式文字列\\n    \\\"\\\"\\\"\\n    # UTCの日時文字列をパースしてdatetimeオブジェクトに変換\\n    utc_time = datetime.strptime(iso_time_str, \\\"%Y-%m-%dT%H:%M:%S.%fZ\\\")\\n    # JSTへの変換（UTC+9時間）\\n    jst_time = utc_time.replace(tzinfo=timezone.utc).astimezone(timezone(timedelta(hours=9)))\\n    # フォーマット変換\\n    jst_time_str = jst_time.strftime(output_format)\\n    return jst_time_str\\n\\n# ■実行日時をJSTのyyyyy/mm/dd hh:mm:ss文字列に変換\\nexecute_timestamp_str = convert_timestamp_iso_to_jst(iso_time_str=execute_timestamp_iso_str, output_format=\\\"%Y/%m/%d %H:%M:%S\\\")\\n# print(f\\\"{datetime.strftime(datetime.now(), '%Y/%m/%dT%H:%M:%S')} DEBUG (MyTransformAddTimestamp) execute_timestamp_str:{execute_timestamp_str}\\\")\\n\\n# DataFrameの取得\\ndf = dfc.select(*list(dfc.keys())).toDF()\\n\\n# JSTタイムスタンプカラムを追加\\ndf = df.withColumn(add_column_name, lit(execute_timestamp_str))\\n\\n# print(f\\\"{datetime.strftime(datetime.now(), '%Y/%m/%dT%H:%M:%S')} INFO (MyTransformAddTimestamp) end\\\")\\n# DynamicFrameに変換して返す\\noutput_dyf = DynamicFrame.fromDF(df, glueContext, \\\"output\\\")\\nreturn DynamicFrameCollection({\\\"CustomTransform0\\\": output_dyf}, glueContext)\",\"Inputs\":[\"node-1733131877532\"],\"Name\":\"【手動アップロード必須】データ統合基盤処理日時付加\",\"OutputSchemas\":[{\"Columns\":[{\"Name\":\"date\",\"Type\":\"string\"},{\"Name\":\"week\",\"Type\":\"string\"},{\"Name\":\"weekday_holidays\",\"Type\":\"string\"},{\"Name\":\"schedule_type\",\"Type\":\"string\"},{\"Name\":\"holiday_name\",\"Type\":\"string\"},{\"Name\":\"year_month\",\"Type\":\"string\"},{\"Name\":\"quarter\",\"Type\":\"string\"},{\"Name\":\"fiscal_year\",\"Type\":\"string\"},{\"Name\":\"orion_process_datetm\",\"Type\":\"string\"}]}]}},\"node-1731895939959\":{\"SelectFromCollection\":{\"Index\":0,\"Inputs\":[\"node-1731895901595\"],\"Name\":\"【手動アップロード必須】加工後処理(データ統合基盤処理日時付加)\"}},\"node-1740551674810\":{\"SelectFromCollection\":{\"Index\":0,\"Inputs\":[\"node-1740551605129\"],\"Name\":\"【加工後必須】加工後処理(日付文字列の桁揃え)\"}},\"node-1733131877532\":{\"SelectFromCollection\":{\"Index\":0,\"Inputs\":[\"node-1735205236158\"],\"Name\":\"【加工時必須】加工後処理(定義した日付フォーマットへ変換)\"}}}",
  "sourceControlDetails" : {
    "provider" : "GITHUB",
    "repository" : "ORioN_nonPIA",
    "branch" : "master",
    "folder" : "orion_prd_etl-job_normalization_calendar"
  }
}