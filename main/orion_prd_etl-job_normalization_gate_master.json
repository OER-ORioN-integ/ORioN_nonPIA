{
  "name" : "orion_prd_etl-job_normalization_gate_master",
  "jobMode" : "VISUAL",
  "description" : "",
  "role" : "arn:aws:iam::142980225941:role/orion_prd_glue-role",
  "executionProperty" : {
    "maxConcurrentRuns" : 1
  },
  "command" : {
    "name" : "glueetl",
    "scriptLocation" : "s3://orion-prd-etljob/scripts/orion_prd_etl-job_normalization_gate_master.py",
    "pythonVersion" : "3"
  },
  "defaultArguments" : {
    "--enable-metrics" : "true",
    "--spark-event-logs-path" : "s3://aws-glue-assets-142980225941-ap-northeast-1/sparkHistoryLogs/",
    "--enable-job-insights" : "false",
    "--enable-glue-datacatalog" : "true",
    "--EXECUTE_TIMESTAMP_ISO_STR" : "2024-11-01T12:23:45.123Z",
    "--SOURCE_SYSTEM" : "MANUAL",
    "--job-bookmark-option" : "job-bookmark-disable",
    "--DATA_NAME" : "gate_master",
    "--job-language" : "python",
    "--TempDir" : "s3://orion-prd-etljob/tmp/"
  },
  "maxRetries" : 0,
  "allocatedCapacity" : 2,
  "timeout" : 120,
  "maxCapacity" : 2.0,
  "glueVersion" : "4.0",
  "numberOfWorkers" : 2,
  "workerType" : "G.1X",
  "executionClass" : "STANDARD",
  "codeGenConfigurationNodes" : "{\"node-1735275517114\":{\"SelectFromCollection\":{\"Index\":0,\"Inputs\":[\"node-1735275296195\"],\"Name\":\"【加工後必須】コーナーコード（生成）\"}},\"node-1733128322914\":{\"CustomCode\":{\"ClassName\":\"MyTransform\",\"Code\":\"import zlib\\nfrom pyspark.sql.functions import udf, col, when\\nfrom pyspark.sql.types import StringType\\n\\n### 作成時の修正箇所ここから ###\\n# 入力項目名と出力項目名の設定\\n入力項目名リスト = [\\\"orion_sta_code\\\"]\\n出力項目名リスト = [\\\"orion_sta_code\\\"]\\n### 作成時の修正箇所ここまで ###\\n\\n# ハッシュ化本体を関数で定義\\ndef hashing(target_str):\\n    # CRC32ハッシュを計算し、HEX形式に変換\\n    return format(zlib.crc32(target_str.encode()), '08x')\\n\\n# UDF(ユーザ定義関数)化して、項目名を引数として利用できるようにする\\nhashing_udf = udf(lambda x: hashing(x) if x else \\\"\\\", StringType())\\n\\n# DataFrameの取得\\ndf = dfc.select(list(dfc.keys())[0]).toDF()\\n\\n# ループ処理で各項目を変換\\nfor 入力項目名, 出力項目名 in zip(入力項目名リスト, 出力項目名リスト):\\n    df = df.withColumn(\\n        出力項目名,\\n        when(col(入力項目名).isNull() | (col(入力項目名) == \\\"\\\"), \\\"\\\").otherwise(hashing_udf(col(入力項目名)))\\n    )\\n\\n# DynamicFrameに変換して返す\\noutput_dyf = DynamicFrame.fromDF(df, glueContext, \\\"output\\\")\\nreturn DynamicFrameCollection({\\\"CustomTransform0\\\": output_dyf}, glueContext)\\n\",\"Inputs\":[\"node-1727675890558\"],\"Name\":\"CRC32ハッシュ化変換\",\"OutputSchemas\":[{\"Columns\":[{\"Name\":\"id\",\"Type\":\"string\"},{\"Name\":\"orion_sta_code\",\"Type\":\"string\"},{\"Name\":\"corner_code\",\"Type\":\"string\"},{\"Name\":\"corner_name\",\"Type\":\"string\"}]}]}},\"node-1733128846449\":{\"SelectFromCollection\":{\"Index\":0,\"Inputs\":[\"node-1733128322914\"],\"Name\":\"【加工後必須】CRC32ハッシュ化変換\"}},\"node-1727674889392\":{\"S3CsvSource\":{\"AdditionalOptions\":{\"EnableSamplePath\":true,\"SamplePath\":\"s3://orion-prd-work/MANUAL/gate_master/schema/gate_master_schema.csv\"},\"Escaper\":\"\\\\\",\"Exclusions\":[],\"Name\":\"【必須】連携された匿名化済みのデータ\",\"OptimizePerformance\":false,\"OutputSchemas\":[{\"Columns\":[{\"Name\":\"id\",\"Type\":\"string\"},{\"Name\":\"orion_sta_code\",\"Type\":\"string\"},{\"Name\":\"corner_code\",\"Type\":\"string\"},{\"Name\":\"corner_name\",\"Type\":\"string\"},{\"Name\":\"\",\"Type\":\"string\"},{\"Name\":\"col5\",\"Type\":\"string\"}]}],\"Paths\":[\"s3://orion-prd-work/MANUAL/gate_master/raw_tmp/\"],\"QuoteChar\":\"quote\",\"Separator\":\"comma\",\"WithHeader\":true}},\"node-1735275296195\":{\"CustomCode\":{\"ClassName\":\"MyTransform_combine_corner_code_gen\",\"Code\":\"from pyspark.sql.functions import col, concat\\nfrom awsglue.dynamicframe import DynamicFrame\\n\\n# データフレームの取得\\ndf = dfc.select(list(dfc.keys())[0]).toDF()\\n\\n# 入力カラム名のリスト\\ninput_columns_list = [\\n    (\\\"orion_sta_code\\\", \\\"corner_code\\\"),\\n]\\n    \\n# 出力カラム名のリスト\\noutput_columns_list = [\\n    \\\"corner_code_gen\\\",\\n]\\n\\n# 各カラムセットに対して結合と新しいカラムの追加\\nfor input_columns, output_column in zip(input_columns_list, output_columns_list):\\n    df = df.withColumn(output_column, concat(col(input_columns[0]), col(input_columns[1])))\\n\\n# DynamicFrameに変換\\noutput_dyf = DynamicFrame.fromDF(df, glueContext, \\\"output\\\")\\nreturn DynamicFrameCollection({\\\"CustomTransform0\\\": output_dyf}, glueContext)\\n\",\"Inputs\":[\"node-1733128846449\"],\"Name\":\"【加工】コーナーコード（生成）\",\"OutputSchemas\":[{\"Columns\":[{\"Name\":\"id\",\"Type\":\"string\"},{\"Name\":\"orion_sta_code\",\"Type\":\"string\"},{\"Name\":\"corner_code\",\"Type\":\"string\"},{\"Name\":\"corner_name\",\"Type\":\"string\"},{\"Name\":\"corner_code_gen\",\"Type\":\"string\"}]}]}},\"node-1727675890558\":{\"ApplyMapping\":{\"Inputs\":[\"node-1727674889392\"],\"Mapping\":[{\"Dropped\":false,\"FromPath\":[\"id\"],\"FromType\":\"string\",\"ToKey\":\"id\",\"ToType\":\"varchar\"},{\"Dropped\":false,\"FromPath\":[\"orion_sta_code\"],\"FromType\":\"string\",\"ToKey\":\"orion_sta_code\",\"ToType\":\"string\"},{\"Dropped\":false,\"FromPath\":[\"corner_code\"],\"FromType\":\"string\",\"ToKey\":\"corner_code\",\"ToType\":\"varchar\"},{\"Dropped\":false,\"FromPath\":[\"corner_name\"],\"FromType\":\"string\",\"ToKey\":\"corner_name\",\"ToType\":\"varchar\"},{\"Dropped\":true,\"FromPath\":[\"\"],\"FromType\":\"string\",\"ToKey\":\"\",\"ToType\":\"string\"},{\"Dropped\":true,\"FromPath\":[\"col5\"],\"FromType\":\"string\",\"ToKey\":\"col5\",\"ToType\":\"string\"}],\"Name\":\"【必須】データ型を変換\"}},\"node-1728609073799\":{\"CustomCode\":{\"ClassName\":\"MyTransformOutputOneFileParquet\",\"Code\":\"from datetime import datetime, timedelta, timezone\\nimport boto3\\nfrom awsglue.utils import getResolvedOptions\\nfrom pyspark.sql import DataFrame\\n\\n### 作成時の修正箇所ここから ###\\n#  本ノードは作成時のパラメータ設定不要です。このままお使いください。\\n### 作成時の修正箇所ここまで ###\\n\\nprint(f\\\"{datetime.strftime(datetime.now(), '%Y/%m/%dT%H:%M:%S')} INFO (MyTransformOutputOneFileParquet) start\\\")\\n\\n# Glueジョブ引数の取得\\nglue_params = getResolvedOptions(sys.argv, [\\\"SOURCE_SYSTEM\\\", \\\"DATA_NAME\\\", \\\"EXECUTE_TIMESTAMP_ISO_STR\\\"])\\nprint(f\\\"{datetime.strftime(datetime.now(), '%Y/%m/%dT%H:%M:%S')} DEBUG (MyTransformOutputOneFileParquet) glue_params:{glue_params}\\\")\\n\\n# 連携元システム名（DMP/ONE/OCTPASS/MANUAL）\\nsource_system = glue_params.get(\\\"SOURCE_SYSTEM\\\", None)\\n# データ名（物理テーブル名）\\ndata_name = glue_params.get(\\\"DATA_NAME\\\", None)\\n# 実行日時\\nexecute_timestamp_iso_str = glue_params.get(\\\"EXECUTE_TIMESTAMP_ISO_STR\\\", None)\\n\\n# プレフィックスヘッド\\nprefix_head = f\\\"{source_system}/{data_name}\\\"\\n\\n# 作業用バケット\\nwork_bucket = \\\"orion-prd-work\\\"\\n# workディレクトリ\\nwork_dir = f\\\"{prefix_head}/raw_work/\\\"\\n# 一時出力先s3パス\\nwork_s3_path = f\\\"s3://{work_bucket}/{work_dir}\\\"\\n\\n# DataFrameの取得\\ndf = dfc.select(list(dfc.keys())[0]).toDF()\\n\\n# workフォルダにparquet形式で出力\\ndf.coalesce(1).write.option(\\\"compression\\\", \\\"snappy\\\").mode(\\\"overwrite\\\").parquet(work_s3_path)\\n\\n# 関数定義\\ndef get_process_timestamp_from_df(df: DataFrame, column_name: str) -> str:\\n    \\\"\\\"\\\"DFからデータ統合基盤処理日時 文字列を取得する\\n    Args:\\n        df (pysoar.sql.DataFrame): データフレーム\\n        column_name (str): データ統合基盤処理日時項目名\\n    Returns:\\n        str: yyyymmddhhmmss\\n    \\\"\\\"\\\"\\n    # JSTタイムスタンプカラムの値を取得（yyyy/mm/dd hh:mm:ss形式）\\n    orion_process_datetm = df.select(column_name).first()[0]\\n    # yyyymmddhhmmss形式に変換\\n    res_datetm_str = datetime.strptime(orion_process_datetm, \\\"%Y/%m/%d %H:%M:%S\\\").strftime(\\\"%Y%m%d%H%M%S\\\")\\n    return res_datetm_str\\n\\ndef convert_timestamp_iso_to_jst(iso_time_str: str, output_format: str) -> str:\\n    \\\"\\\"\\\"ISO日時文字列を指定フォーマットに変換\\n    Args:\\n        iso_time_str (str): ISO日時文字列\\n        output_format (str): 出力フォーマット\\n    Returns:\\n        str: 指定フォーマット形式文字列\\n    \\\"\\\"\\\"\\n    # UTCの日時文字列をパースしてdatetimeオブジェクトに変換\\n    utc_time = datetime.strptime(iso_time_str, \\\"%Y-%m-%dT%H:%M:%S.%fZ\\\")\\n    # JSTへの変換（UTC+9時間）\\n    jst_time = utc_time.replace(tzinfo=timezone.utc).astimezone(timezone(timedelta(hours=9)))\\n    # フォーマット変換\\n    jst_time_str = jst_time.strftime(output_format)\\n    return jst_time_str\\n\\n# ■実行日時をJSTのyyyyymmddhhmmss文字列に変換\\n# DFの処理日時項目名\\nORION_PROCESS_DATETM = \\\"orion_process_datetm\\\"\\nif ORION_PROCESS_DATETM in df.columns and df.select(ORION_PROCESS_DATETM).count() != 0:\\n    execute_timestamp_str = get_process_timestamp_from_df(df=df, column_name=ORION_PROCESS_DATETM)\\n    print(f\\\"{datetime.strftime(datetime.now(), '%Y/%m/%dT%H:%M:%S')} DEBUG (get_process_timestamp_from_df) execute_timestamp_str:{execute_timestamp_str}\\\")\\nelse:\\n    execute_timestamp_str = convert_timestamp_iso_to_jst(iso_time_str=execute_timestamp_iso_str, output_format=\\\"%Y%m%d%H%M%S\\\")\\n    print(f\\\"{datetime.strftime(datetime.now(), '%Y/%m/%dT%H:%M:%S')} DEBUG (convert_timestamp_iso_to_jst) execute_timestamp_str:{execute_timestamp_str}\\\")\\n\\n#  DWHバケット\\ndwh_bucket = \\\"orion-prd-dwh\\\"\\n# 連携先ディレクトリ\\nreceive_prefix = f\\\"{prefix_head}/receive\\\"\\n# 連携ファイル名\\nfile_name = f\\\"{data_name}_dwh_{execute_timestamp_str}.snappy.parquet\\\"\\n# 連携先key\\nfile_key = f\\\"{receive_prefix}/{file_name}\\\"\\n\\n# S3クライアントを使用してworkフォルダに出力したファイルをリネームして移動\\ns3 = boto3.client(\\\"s3\\\")\\nresponse = s3.list_objects_v2(Bucket=work_bucket, Prefix=work_dir)\\nfor obj in response.get(\\\"Contents\\\", []):\\n    if obj[\\\"Key\\\"].endswith(\\\".parquet\\\"):\\n        # ソース情報設定\\n        copy_source = {\\\"Bucket\\\": work_bucket, \\\"Key\\\": obj[\\\"Key\\\"]}\\n        print(f\\\"{datetime.strftime(datetime.now(), '%Y/%m/%dT%H:%M:%S')} DEBUG (MyTransformOutputOneFileParquet) copy_source:{copy_source}, dwh_bucket:{dwh_bucket}, file_key:{file_key}\\\")\\n        # コピーを実行\\n        s3.copy_object(CopySource=copy_source, Bucket=dwh_bucket, Key=file_key)\\n        # 削除を実行\\n        s3.delete_object(Bucket=work_bucket, Key=obj[\\\"Key\\\"])\\n        break\\n\\nprint(f\\\"{datetime.strftime(datetime.now(), '%Y/%m/%dT%H:%M:%S')} INFO (MyTransformOutputOneFileParquet) end\\\")\\n\",\"Inputs\":[\"node-1731895939959\"],\"Name\":\"【必須】１ファイルでDWHバケットに出力\"}},\"node-1731895901595\":{\"CustomCode\":{\"ClassName\":\"MyTransformAddTimestamp\",\"Code\":\"from datetime import datetime, timedelta, timezone\\nfrom awsglue.utils import getResolvedOptions\\nfrom pyspark.sql.functions import lit\\n\\n### 作成時の修正箇所ここから ###\\n#  本ノードは作成時のパラメータ設定不要で、このままお使いください。\\n### 作成時の修正箇所ここまで ###\\n\\nprint(f\\\"{datetime.strftime(datetime.now(), '%Y/%m/%dT%H:%M:%S')} INFO (MyTransformAddTimestamp) start\\\")\\n\\n# Glueジョブ引数の取得\\nglue_params = getResolvedOptions(sys.argv, [\\\"EXECUTE_TIMESTAMP_ISO_STR\\\"])\\nprint(f\\\"{datetime.strftime(datetime.now(), '%Y/%m/%dT%H:%M:%S')} DEBUG (MyTransformAddTimestamp) glue_params:{glue_params}\\\")\\n\\n# 実行日時\\nexecute_timestamp_iso_str = glue_params.get(\\\"EXECUTE_TIMESTAMP_ISO_STR\\\", None)\\n\\n# 追加項目名\\nadd_column_name = \\\"orion_process_datetm\\\"\\n\\n# 関数定義\\ndef convert_timestamp_iso_to_jst(iso_time_str: str, output_format: str) -> str:\\n    \\\"\\\"\\\"ISO日時文字列を指定フォーマットに変換\\n    Args:\\n        iso_time_str (str): ISO日時文字列\\n        output_format (str): 出力フォーマット\\n    Returns:\\n        str: 指定フォーマット形式文字列\\n    \\\"\\\"\\\"\\n    # UTCの日時文字列をパースしてdatetimeオブジェクトに変換\\n    utc_time = datetime.strptime(iso_time_str, \\\"%Y-%m-%dT%H:%M:%S.%fZ\\\")\\n    # JSTへの変換（UTC+9時間）\\n    jst_time = utc_time.replace(tzinfo=timezone.utc).astimezone(timezone(timedelta(hours=9)))\\n    # フォーマット変換\\n    jst_time_str = jst_time.strftime(output_format)\\n    return jst_time_str\\n\\n# ■実行日時をJSTのyyyyy/mm/dd hh:mm:ss文字列に変換\\nexecute_timestamp_str = convert_timestamp_iso_to_jst(iso_time_str=execute_timestamp_iso_str, output_format=\\\"%Y/%m/%d %H:%M:%S\\\")\\nprint(f\\\"{datetime.strftime(datetime.now(), '%Y/%m/%dT%H:%M:%S')} DEBUG (MyTransformAddTimestamp) execute_timestamp_str:{execute_timestamp_str}\\\")\\n\\n# DataFrameの取得\\ndf = dfc.select(*list(dfc.keys())).toDF()\\n\\n# JSTタイムスタンプカラムを追加\\ndf = df.withColumn(add_column_name, lit(execute_timestamp_str))\\n\\nprint(f\\\"{datetime.strftime(datetime.now(), '%Y/%m/%dT%H:%M:%S')} INFO (MyTransformAddTimestamp) end\\\")\\n# DynamicFrameに変換して返す\\noutput_dyf = DynamicFrame.fromDF(df, glueContext, \\\"output\\\")\\nreturn DynamicFrameCollection({\\\"CustomTransform0\\\": output_dyf}, glueContext)\",\"Inputs\":[\"node-1735275517114\"],\"Name\":\"【手動アップロード必須】データ統合基盤処理日時付加\"}},\"node-1731895939959\":{\"SelectFromCollection\":{\"Index\":0,\"Inputs\":[\"node-1731895901595\"],\"Name\":\"【手動アップロード必須】加工後処理(データ統合基盤処理日時付加)\"}}}",
  "sourceControlDetails" : {
    "provider" : "GITHUB",
    "repository" : "ORioN_nonPIA",
    "branch" : "master",
    "folder" : "main"
  }
}